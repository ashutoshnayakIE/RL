{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Dynamic Programming</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic programming has a long history before the popularity of Reinforcement Learning. Dynamic programming is used to take sequentially actions based on past decisions, current conditions, expected future rewards. We will consider Markov Decision Process (MDP) where the current conditions is brought upon by the decisions made in the past and change how the environment reacted to those decisions (we cannot go back in time and change our decisions). In MDP, we take decision based on current conditions and what can we do get maximum expected reward (not just immediate but long term reward). \n",
    "\n",
    "To simplify, we will consider discrete time environment where actions are taken in discrete time slots rather than continuous time. If the system is continuous, we can always time discrete (for example, take decisions every 5 minutes). In driving, for example, we take decisions when we reach a city (node in our model).\n",
    "\n",
    "THE books on Dynamic Programming (DP) and Reinforcement Learning (RL) are:\n",
    "1. http://athenasc.com/dpbook.html  (DP)\n",
    "2. http://www.incompleteideas.net/book/the-book-2nd.html (RL)\n",
    "\n",
    "These books are very well written, very easy to follow and understand the concepts. This tutorial is just to give an idea of Dynamic programming using one example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this brief introduction, we will go through some examples of simple dynamic programming problems and lay a background for model day Reinforcement Learning. First, the most important figure for all of RL. In DP, the agent is the user (manual or automated) who takes decisions for the next step.\n",
    "\n",
    "<img src='figures/RL.png'></img>\n",
    "<center>Figure 1. Reinforcement Learning</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure explains DP mathematically as what we a re trying to achieve when taking sequential decisions. We aim for long term rewards, accumulated over time (for example, winning at the end of the game and not caring about immediate reward like taking out a pawn of the opponent but actually exposing to opponent). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Traveling Salesman problem</h2>\n",
    "\n",
    "Consider a traveling salesman problem. In this problem, a salesman has to visit cover n number of cities or location from warehouse and come back after visiting each city. We can also think of it as amazon delivery. It has to deliver all the packages in the city. The salesman could consider any possible sequence of how they visit the cities. \n",
    "\n",
    "In the example, if we have four cities, there are 4!=24 ways in which cities can be covered (A city has to be visited once). In the example from the DP book, the distance between the four cities is given in the matrix form. The objective is to find a sequence that minimizes the total distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global distance, cities\n",
    "\n",
    "distance = [\n",
    "    [0,5,1,15],\n",
    "    [5,0,20,4],\n",
    "    [1,20,0,3],\n",
    "    [15,4,3,0]\n",
    "]\n",
    "cities = ['A','B','C','D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(seq):\n",
    "    cost = 0\n",
    "    \n",
    "    for j in range(1,4):\n",
    "        c1 = cities.index(seq[j-1])\n",
    "        c2 = cities.index(seq[j])\n",
    "        cost += distance[c1][c2]\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best sequence: ['A', 'C', 'D', 'B'] cost of best sequence: 8\n"
     ]
    }
   ],
   "source": [
    "# generating all possible sequences\n",
    "\n",
    "# BRUTE FORCE\n",
    "# we can directly calculate the cost here for all possible sequences (but see how fast the number of choices increase)\n",
    "# for 4 cities, it checks 4^4 options\n",
    "# intelligently checking for all options will lead us to check just 24 sequences. But this grows very fast as well\n",
    "\n",
    "best_cost = 10000\n",
    "best_seq  = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        for k in range(4):\n",
    "            for l in range(4):\n",
    "                seq  = [cities[i],cities[j],cities[k],cities[l]] \n",
    "                \n",
    "                # following line checks if non of the city is visited twice\n",
    "                if seq.count('A') == 1 and seq.count('B') == 1 and seq.count('C') == 1 and seq.count('D') == 1:\n",
    "                    cost = cost_function(seq)\n",
    "                    if cost < best_cost:\n",
    "                        best_cost = cost\n",
    "                        best_seq  = seq\n",
    "                     \n",
    "print('best sequence:', best_seq, 'cost of best sequence:', best_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "220.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
